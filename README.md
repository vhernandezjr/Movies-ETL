# Movies-ETL

*ETL - Extract,  Transform, and Load*
### ETL Movies Analysis using Python, RegEx and SQL Databases

### Background
The data used for analysis exists in multiple places and forms. In order to perform the data analysis, the data needs to be cleaned, formatted and structured. The data pipeline process **ETL â€“ Extract, Transform, and Load** is a core concept in data engineering, ensuring that data is consistent and allows for automatization of data wrangling. Without a consistency in the process, data integrity is lost.

Amazing Prime, is a sponsor for a contest the: *hackathon*. Participants of the *hackathon* must use the ETL process to perform analyses on the movie data set. The process:

-	*Extracting* data from two different sources. 
    - web scrape Wiki
    - data from Kaggle
-	*Transforming* data using Jupyter Notebook, Python, Pandas and RegEx.
-	*Loading* data using PostgreSQL and pgAdmin to contain the final data set.

Enviroment:
-	Python
Software:
-	Jupyter Notebook
-	PostgreSQL and PgAdmin

## Objective

The goal for the project was to create a automated pipeline that extracts, transform and loads data. This analysis consists of four parts, where each step is building upon the ETL process. The ETL process for this project consist of four jupyter notebook files.  

